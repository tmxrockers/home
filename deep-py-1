import openpyxl
import os
import pandas as pd
import logging
from datetime import datetime

# Generate log file name with current date
current_date = datetime.now().strftime("%Y-%m-%d")
log_file = f"DataMasking_{current_date}.log"

# Set up logging
logging.basicConfig(
    filename=log_file,
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logging.info("Data Masking Script Started")

# Read metadata from Alteryx input
metadata_df = pd.read_excel("DataMasking.xlsx", sheet_name=0)
logging.info("Metadata file loaded successfully")

# Convert metadata into a dictionary grouped by Workflow Type and File Path
grouped_rules = metadata_df.groupby(["Workflow Type", "File Path", "Header Row"])
logging.info("Metadata grouped by Workflow Type, File Path, and Header Row")

def mask_email(value):
    """Mask an email address while keeping the domain intact."""
    if "@" in value:
        username, domain = value.split("@", 1)
        masked_username = "".join("x" if c.isalpha() else c for c in username)
        return f"{masked_username}@{domain}"
    return value  # Return unchanged if not a valid email

def apply_masking_column(column, pattern, mask_value, referenced_data=None, condition_columns=None, referenced_columns=None, condition_type=None, main_df=None, output_column=None):
    """Apply masking to an entire column."""
    if pattern == "Constant":
        return [mask_value] * len(column)
    elif pattern == "Prefix":
        return [f"{mask_value}{val}" for val in column]
    elif pattern == "Suffix":
        return [f"{val}{mask_value}" for val in column]
    elif pattern == "Email":
        return [mask_email(str(val)) for val in column]
    elif pattern == "Null":
        return [None] * len(column)
    elif pattern == "Referenced File":
        if referenced_data is not None and condition_columns is not None and referenced_columns is not None and main_df is not None and output_column is not None:
            if len(condition_columns) != len(referenced_columns):
                logging.error(f"Error: Condition columns and referenced columns must have the same length.")
                return column  # Return original column if lengths don't match

            masked_column = []
            for idx, value in enumerate(column):
                match_found = False
                for ref_row in referenced_data:
                    match = True
                    for cond_col, ref_col in zip(condition_columns, referenced_columns):
                        cond_value = main_df[cond_col].iloc[idx]  # Get condition value from main dataset
                        if cond_value is None:
                            logging.error(f"Error: Condition column '{cond_col}' not found in main dataset.")
                            match = False
                            break
                        logging.debug(f"Checking condition: main_df[{cond_col}].iloc[{idx}] = {cond_value} against ref_row[{ref_col}] = {ref_row.get(ref_col)}")
                        if condition_type == "Equals" and ref_row.get(ref_col) != cond_value:
                            match = False
                            break
                        elif condition_type == "Contains" and ref_row.get(ref_col, "") not in cond_value:
                            match = False
                            break
                    if match:
                        logging.debug(f"Match found for index {idx}: {ref_row[output_column]}")
                        masked_column.append(ref_row[output_column])  # Use the output column
                        match_found = True
                        break
                if not match_found:
                    logging.debug(f"No match found for index {idx}, keeping original value: {value}")
                    masked_column.append(value)  # Keep original value if no match found
            return masked_column
    return column  # Default: No masking if pattern is unknown

def is_row_empty(row):
    """Check if all values in a row are NULL or empty."""
    return all(cell.value is None or str(cell.value).strip() == "" for cell in row)

def ensure_text_format(sheet, header_row):
    """Ensure all data is treated as text to prevent misinterpretation."""
    for row in sheet.iter_rows(min_row=header_row + 1):
        for cell in row:
            # If cell is numeric, no change
            if isinstance(cell.value, (int, float)):
                continue

            # If the value is a string formatted as a date, treat it as text
            elif isinstance(cell.value, str) and "MM/dd/yyyy" in cell.number_format:
                cell.value = str(cell.value)  # Convert date to string
                cell.number_format = "@"  # Force text format

            elif isinstance(cell.value, str):
                cell.value = cell.value.strip()  # Clean text data

            # Force text format in all cases
            cell.number_format = "@"

def ensure_valid_headers(sheet, header_row):
    """Ensure headers are correctly formatted as strings to avoid issues."""
    headers = []
    for cell in sheet[header_row]:
        if isinstance(cell.value, (int, float)):
            cell.value = f"Column {cell.column}"  # Rename numerical headers
        elif cell.value is None or str(cell.value).strip() == "":
            cell.value = f"Column {cell.column}"  # Rename blank headers
        else:
            cell.value = str(cell.value).strip()  # Convert to string
        cell.number_format = "@"  # Force text format
        headers.append(cell.value)
    return headers

def read_referenced_file(file_path, sheet_name):
    """Read the referenced file and return the data as a list of dictionaries."""
    try:
        wb = openpyxl.load_workbook(file_path)
        sheet = wb[sheet_name]
        headers = [cell.value for cell in sheet[1]]
        logging.info(f"Headers in {file_path} (Sheet: {sheet_name}): {headers}")
        data = []
        for row in sheet.iter_rows(min_row=2):
            row_data = {}
            for idx, cell in enumerate(row):
                row_data[headers[idx]] = cell.value
            data.append(row_data)
        return data
    except Exception as e:
        logging.error(f"Error reading referenced file {file_path}: {e}")
        return None

def mask_excel_file(file_path, header_row, rules):
    """Mask Excel data while preserving formatting."""
    try:
        logging.info(f"Processing file: {file_path}")
        # Read the main dataset into a pandas DataFrame
        main_df = pd.read_excel(file_path, header=header_row - 1)
        logging.info("Main dataset loaded successfully")

        # Add temporary columns for referenced-based masking
        for column_name, pattern, _, _, referenced_file_path, referenced_sheet, condition_column, referenced_column, _, include_in_output, _ in rules:
            if include_in_output == "No" and column_name not in main_df.columns:
                main_df[column_name] = None  # Add temporary column with None values
                logging.debug(f"Added temporary column: {column_name}")

        # Process each masking rule
        for column_name, pattern, mask_value, condition, referenced_file_path, referenced_sheet, condition_column, referenced_column, condition_type, include_in_output, output_column in rules:
            if column_name not in main_df.columns:
                logging.warning(f"Column '{column_name}' not found in the main dataset.")
                continue

            logging.info(f"Applying masking to column: {column_name}")
            # Apply masking to the column
            if pattern == "Referenced File":
                referenced_data = read_referenced_file(referenced_file_path, referenced_sheet)
                condition_columns = condition_column.split(";") if condition_column else []
                referenced_columns = referenced_column.split(";") if referenced_column else []
                main_df[column_name] = apply_masking_column(
                    main_df[column_name], pattern, mask_value, referenced_data, condition_columns, referenced_columns, condition_type, main_df, output_column
                )
            else:
                main_df[column_name] = apply_masking_column(main_df[column_name], pattern, mask_value)

        # Remove columns marked as "No" in Include in Output?
        columns_to_remove = [column_name for column_name, _, _, _, _, _, _, _, _, include_in_output, _ in rules if include_in_output == "No"]
        main_df.drop(columns=columns_to_remove, inplace=True)
        logging.info(f"Removed temporary columns: {columns_to_remove}")

        # Save masked file using openpyxl to preserve formatting
        wb = openpyxl.load_workbook(file_path)
        sheet = wb.active

        # Ensure valid headers and text format
        ensure_valid_headers(sheet, header_row)
        ensure_text_format(sheet, header_row)

        # Write the masked data back to the Excel file
        previous_row_empty = False  # Flag to track empty row condition
        for row_idx, row in enumerate(main_df.itertuples(index=False), start=header_row + 1):
            if is_row_empty(sheet[row_idx]):  # Check if the row is empty
                previous_row_empty = True
                logging.debug(f"Empty row found at index {row_idx}. Skipping further processing.")
                continue  # Skip masking for empty rows

            if previous_row_empty:
                logging.info("Skipping masking due to NULL row condition.")
                break  # Stop masking if previous row was empty

            for col_idx, value in enumerate(row, start=1):
                sheet.cell(row=row_idx, column=col_idx, value=value)

        # Save masked file in a new folder
        base_dir = os.path.dirname(file_path)
        masked_folder = os.path.join(base_dir, "Masked_Files")
        os.makedirs(masked_folder, exist_ok=True)
        logging.info(f"Created masked folder: {masked_folder}")

        output_file = os.path.join(masked_folder, os.path.basename(file_path))
        wb.save(output_file)
        logging.info(f"Masked file saved: {output_file}")

    except Exception as e:
        logging.error(f"Error processing {file_path}: {e}")

# Process each workflow type and file separately
for (workflow_type, file_path, header_row), group in grouped_rules:
    masking_rules = list(zip(
        group["Column Name"],
        group["Masking Pattern"],
        group["Masking Value"],
        group["Masking Value Filter"],
        group["Referenced Lookup File Path"],
        group["Referenced Lookup Sheet"],
        group["Condition Column"],
        group["Referenced Lookup Column"],
        group["Referenced Condition Type"],
        group["Include in Output? (Yes/No)"],
        group["Referenced Lookup Output Column"]
    ))
    mask_excel_file(file_path, int(header_row), masking_rules)

logging.info("Data Masking Script Completed")
